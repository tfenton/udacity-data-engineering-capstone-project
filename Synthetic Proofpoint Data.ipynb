{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydbgen import pydbgen\n",
    "import os\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "def randomString(stringLength):\n",
    "    \"\"\"Generate a random string with the combination of lowercase and uppercase letters \"\"\"\n",
    "    letters = string.ascii_letters\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 1000000\n",
    "START_DATE = '2019-09-15'\n",
    "END_DATE = '2019-09-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomDir():\n",
    "    randint = random.randint(0,64)\n",
    "    if randint > 31:\n",
    "        drive_letters = ['C:', 'D:', 'H:','/', 'Z:']\n",
    "        file_extensions = ['.a','.asm','.asp','.awk','.bat','.bmp','.btm','.BTM','.c','.class','.cmd','.CPP','.csv','.cur','.cxx','.CXX','.db','.def','.DES','.dlg','.dll','.don','.dpc','.dpj','.dtd','.dump','.dxp','.eng','.exe','.flt','.fmt','.font','.fp','.ft','.gif','.h','.H','.hdb','.hdl','.hid','.hpp','.hrc','.HRC','.html','.hxx','.Hxx','.HXX','.ico','.idl','.IDL','.ih','.ilb','.inc','.inf','.ini','.inl','.ins','.java','.jar','.jnl','.jpg','.js','.jsp','.kdelnk','.l','.lgt','.lib','.lin','.ll','.LN3','.lng','.lnk','.lnx','.LOG','.lst','.lst','.mac','.MacOS','.map','.mk','.MK','.mod','.NT2','.o','.obj','.par','.pfa','.pfb','.pl','.PL','.plc','.pld','.PLD','.plf','.pm','.pmk','.pre','.PRJ','.prt','.PS','.ptr','.r','.rc','.rdb','.res','.s','.S','.sbl','.scp','.scr','.sda','.sdb','.sdc','.sdd','.sdg','.sdm','.sds','.sdv','.sdw','.sdi','.seg','.SEG','.Set','.sgl','.sh','.sid','.smf','.sms','.so','.sob','.sob','.soc','.sod','.soe','.sog','.soh','.src','.srs','.SSLeay','.Static','.tab','.TFM','.thm','.tpt','.tsc','.ttf','.TTF','.txt','.TXT','.unx','.UNX','.urd','.url','.VMS','.vor','.W32','.wav','.wmf','.xml','.xpm','.xrb','.y','.yxx','.zip',]\n",
    "        path_parts = fake.text(max_nb_chars=randint).split()\n",
    "        path_parts = [word.replace('.','').lower() for word in path_parts]\n",
    "        return os.path.join(random.choice(drive_letters), *path_parts[:-1], path_parts[-1] + random.choice(file_extensions))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_db = pydbgen.pydb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_db.gen_data_series(data_type='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = pd.read_csv('../airflow/data/employees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = my_db.gen_dataframe(50000, fields=['name','email', 'phone'], real_email=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees['address'] = pd.Series([fake.address() for i in tqdm(range(df_employees.shape[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.drop_duplicates(subset=['email']).to_csv('employees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now work on the synthetic email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"guid\"#: \"7QOFtqhH3UxB7va5fFHfw6pCHzT7E1iM\",\n",
    "    ,\"datetime\"#: \"2019-09-01 00:45:50 -0500\", DONE\n",
    "    ,\"sender\"#: \"helpdesk@staefa.com.br\", DONE\n",
    "    ,\"recipients\"#: [ \"brpjbissup@wal-mart.com\" ], \n",
    "    ,\"subject\"#: null,\n",
    "    ,\"attachments\"#: null,\n",
    "    ,\"rule\"#: \"norcpts\",\n",
    "    ,\"action\"#: \"discard\",\n",
    "    ,\"attach_cnt\"#: \"0\",\n",
    "    ,\"rcpt_cnt\"#: \"1\",\n",
    "    ,\"email_size\"#: \"0\",\n",
    "    ,\"log_file\"#: \"201908.gz\",\n",
    "    ,\"log_key_id\"#: \"2uqnqbb41y\"]\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_date = my_db.gen_data_series(DATA_SIZE, data_type='date') + 'T' + my_db.gen_data_series(DATA_SIZE, data_type='time') + 'Z'\n",
    "def random_dates(start, end, n=10):\n",
    "    start_u = start.value//10**9\n",
    "    end_u = end.value//10**9\n",
    "\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_DATES = True\n",
    "# s_date = None\n",
    "# if RANDOM_DATES:\n",
    "    # this line give dates in a random range\n",
    "s_date = pd.Series(random_dates(pd.to_datetime(START_DATE),pd.to_datetime(END_DATE),DATA_SIZE))\n",
    "# else:\n",
    "#     # this line limits dates and times to a single day\n",
    "#     s_date = pd.Series(random_dates(pd.to_datetime('2019-09-14'),pd.to_datetime('2019-09-15'),DATA_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date = s_date.dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date.dt.day.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject of email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_subjects = pd.Series([fake.text(max_nb_chars=64) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_guids = pd.Series([randomString(32) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_senders = pd.Series([random.choice(df_employees.email) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skewed_proba():\n",
    "    pers = np.arange(1,32,1)\n",
    "\n",
    "    # Make each of the last 41 elements 5x more likely\n",
    "    prob = [10.0]*4 + [1.0]*(len(pers)-4)\n",
    "\n",
    "    # Normalising to 1.0\n",
    "    prob /= np.sum(prob)\n",
    "\n",
    "    num_recips = np.random.choice(pers, 1, p=prob)\n",
    "    return num_recips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_recipients = pd.Series([[random.choice(df_employees.email) for i in range(int(get_skewed_proba())) ] for j in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recip count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rcpt_cnt = s_recipients.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attachements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttachments():\n",
    "    dirs = []\n",
    "    for i in range(random.randint(0, 5)):\n",
    "        dir = randomDir() \n",
    "        if dir:\n",
    "            dirs.append(dir)\n",
    "    return dirs\n",
    "\n",
    "s_attachments = pd.Series([getAttachments() for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attachement count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attach_cnt = s_attachments.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [fake.text(10).replace('.','').upper().split()[0] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rule = pd.Series([random.choice(rules) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [fake.text(20).replace('.','').replace(' ','_').upper() for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_action = pd.Series([random.choice(actions) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log key id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_log_key_ids = pd.Series([randomString(8) for i in tqdm(range(int(DATA_SIZE/10)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = [f'20190{i}.gz' for i in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_log_files = pd.Series([random.choice(log_files) for i in tqdm(range(DATA_SIZE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### email size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_email_size = pd.Series(np.random.randint(1024*1024*25, size=DATA_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([s_guids, s_date, s_senders, s_recipients, s_subjects, s_attachments, s_rule, s_action, s_attach_cnt, s_rcpt_cnt, s_email_size, s_log_files, s_log_key_ids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.sort_values(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('synthetic_data'):\n",
    "#     os.mkdir(\"synthetic_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = None\n",
    "for date in tqdm(df_combined.datetime.dt.date.unique()):\n",
    "    df_tmp = df_combined[df_combined.datetime.dt.date == date]\n",
    "    df_tmp.to_csv(f'../airflow/data/{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('synthetic_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.DataFrame(files, columns=['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files['time_created'] = pd.to_datetime(df_files.file_name.apply(os.path.getatime),unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files['time_modified'] = pd.to_datetime(df_files.file_name.apply(os.path.getmtime),unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.time_created.dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files[df_files.time_created.dt.strftime('%Y-%m-%d %H:%M') != df_files.time_modified.dt.strftime('%Y-%m-%d %H:%M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getctime(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getmtime(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getatime(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.stat(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employees to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = pd.read_csv('employees.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.to_csv('../airflow/data/employees.csv', index=None, header=True, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../airflow/data/employees.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(df_employees.head().to_json(orient='records')), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.to_json('/encrypted_vol/jupyter_data/airflow/data/employees.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees.address = df_employees.address.str.replace('\\n',', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employees.json', 'wt') as f:\n",
    "    for i, row in df_employees.iterrows():\n",
    "        f.write(row.to_json()+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head employees.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_employees.email.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proofpoint]",
   "language": "python",
   "name": "conda-env-proofpoint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
